# Glossary: Digital Twin, Gazebo, and Simulation Terms

This glossary provides definitions for key terms used throughout the Digital Twin simulation module.

## A

**Artificial Potential Fields**: A navigation method that uses attractive forces toward goals and repulsive forces from obstacles to guide robot motion.

## B

**Behavior Trees**: A hierarchical structure used for organizing robot behaviors, consisting of control flow nodes and execution nodes that provide modularity and reusability.

## C

**Collision Geometry**: The simplified geometric representation of a robot link used for collision detection in simulation, typically simpler than visual geometry for performance reasons.

## D

**Digital Twin**: A virtual representation of a physical robot or system that accurately models its geometry, physics properties, sensor models, and environmental interactions.

**Differential Drive**: A common robot configuration using two independently controlled wheels on an axis, allowing movement and rotation by varying wheel speeds.

## E

**End Effector**: The tool or grasping mechanism at the end of a robot manipulator arm, designed to interact with the environment.

## F

**Forward Kinematics**: The process of determining the position and orientation of a robot's end effector based on the joint angles of its manipulator.

## G

**Gazebo**: A physics-based simulation environment that provides realistic robot and environment modeling with support for various sensors and physics engines.

**Gazebo Classic**: The traditional version of Gazebo that uses OGRE for rendering and has mature ROS 2 integration, as opposed to newer versions like Gazebo Garden.

## H

**Human-Robot Interaction (HRI)**: The study and implementation of interactions between humans and robots, including communication, collaboration, and safety considerations.

## I

**Inverse Kinematics**: The process of determining the joint angles required to achieve a desired position and orientation of a robot's end effector.

**Inertial Properties**: Physical characteristics of a rigid body including mass, center of mass, and inertia tensor that determine how it responds to forces and torques.

**IMU (Inertial Measurement Unit)**: A sensor that measures acceleration and angular velocity, providing data about a robot's motion and orientation.

## J

**Joint**: A connection between two links in a robot that allows relative motion, with types including fixed, revolute, prismatic, and continuous joints.

## K

**Kinematics**: The study of motion without considering the forces that cause it, including both forward and inverse kinematics in robotics.

## L

**LiDAR (Light Detection and Ranging)**: A sensor technology that measures distances by illuminating targets with laser light and analyzing the reflected light.

## M

**Mobile Robot**: A robot with the ability to move around in its environment, typically using wheels, tracks, or legs for locomotion.

**Model Predictive Control (MPC)**: An advanced control strategy that uses a dynamic model of the system to predict future behavior and optimize control actions over a finite time horizon.

## P

**Physics Engine**: Software that simulates the laws of physics, including collision detection, dynamics, and constraint solving for realistic simulation.

**Point Cloud**: A collection of data points in 3D space, typically generated by 3D scanners or depth sensors like LiDAR or stereo cameras.

**Proportional-Integral-Derivative (PID) Controller**: A control loop feedback mechanism widely used in robotics to minimize the error between desired and actual values.

## R

**ROS (Robot Operating System)**: A flexible framework for writing robot software that provides services like hardware abstraction, device drivers, and message passing.

**ROS 2**: The second generation of the Robot Operating System with improved features including real-time support, security, and better middleware.

**ROS-TCP-Connector**: A communication bridge that enables real-time data exchange between Unity and ROS 2 systems using TCP/IP protocol.

## S

**Sensor Simulation**: The process of generating realistic sensor data in simulation that mimics the behavior of real-world sensors.

**SDF (Simulation Description Format)**: An XML-based format used to describe simulation environments, robots, and objects in Gazebo.

**SLAM (Simultaneous Localization and Mapping)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

**Simulation-First Approach**: A development methodology that emphasizes testing and validating robotic systems in simulation before physical deployment to reduce risk and cost.

## T

**TF (Transform)**: A system in ROS that keeps track of coordinate frame relationships over time, allowing for spatial reasoning between different parts of a robot and its environment.

**Trajectory Planning**: The process of determining a path for a robot to follow that satisfies kinematic and dynamic constraints while avoiding obstacles.

## U

**URDF (Unified Robot Description Format)**: An XML-based format for representing robot models including links, joints, and their physical and kinematic properties.

**Unity**: A cross-platform game engine that provides advanced rendering capabilities and user interaction features for creating high-fidelity digital twins.

## V

**Visual Geometry**: The detailed geometric representation of a robot link used for visualization in simulation environments, often more detailed than collision geometry.

## W

**World File**: An SDF file that defines the simulation environment including static objects, lighting conditions, physics parameters, and initial robot positions.
